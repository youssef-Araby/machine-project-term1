{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a641242e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset configuration\n",
    "CONFIG_PATH = '../data/dataset_config.json'\n",
    "assert os.path.exists(CONFIG_PATH), \"Run 01_data_analysis_processing.ipynb first!\"\n",
    "\n",
    "with open(CONFIG_PATH) as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "DATA_PATH = config['data_path']\n",
    "MEAN, STD = config['mean'], config['std']\n",
    "IMAGE_SIZE = config['image_size']\n",
    "\n",
    "# Hyperparameters\n",
    "OUTPUT_DIR = '../outputs/densenet'\n",
    "MODEL_PATH = os.path.join(OUTPUT_DIR, 'model.pth')\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 10\n",
    "LR = 1e-3\n",
    "SEED = 42\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "print(f\"Data: {DATA_PATH}\")\n",
    "print(f\"Normalization - Mean: {MEAN}, Std: {STD}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc9c0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cached tensor dataset\n",
    "class CachedTensorDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root, augment=False):\n",
    "        dataset = datasets.ImageFolder(root)\n",
    "        self.augment = augment\n",
    "        self.tensors = []\n",
    "        self.targets = []\n",
    "        \n",
    "        print(f\"Caching {len(dataset)} images as tensors...\")\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(MEAN, STD)\n",
    "        ])\n",
    "        \n",
    "        for path, target in tqdm(dataset.samples, desc=\"Loading\"):\n",
    "            img = Image.open(path).convert('RGB')\n",
    "            self.tensors.append(transform(img))\n",
    "            self.targets.append(target)\n",
    "        \n",
    "        self.tensors = torch.stack(self.tensors)\n",
    "        self.targets = torch.tensor(self.targets)\n",
    "        self.classes = dataset.classes\n",
    "        print(f\"Cached tensor shape: {self.tensors.shape}\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.targets)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = self.tensors[idx]\n",
    "        if self.augment:\n",
    "            if torch.rand(1) > 0.5:\n",
    "                x = torch.flip(x, [2])\n",
    "            if torch.rand(1) > 0.5:\n",
    "                x = torch.flip(x, [1])\n",
    "        return x, self.targets[idx]\n",
    "\n",
    "train_dataset = CachedTensorDataset(os.path.join(DATA_PATH, 'train'), augment=True)\n",
    "val_dataset = CachedTensorDataset(os.path.join(DATA_PATH, 'val'), augment=False)\n",
    "test_dataset = CachedTensorDataset(os.path.join(DATA_PATH, 'test'), augment=False)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                          num_workers=0, pin_memory=True, drop_last=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE*2, shuffle=False,\n",
    "                        num_workers=0, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE*2, shuffle=False,\n",
    "                         num_workers=0, pin_memory=True)\n",
    "\n",
    "class_names = train_dataset.classes\n",
    "num_classes = len(class_names)\n",
    "print(f\"\\nClasses: {class_names}\")\n",
    "print(f\"Train: {len(train_dataset)} | Val: {len(val_dataset)} | Test: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b15806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DenseNet-121 with frozen backbone\n",
    "model = models.densenet121(weights=models.DenseNet121_Weights.IMAGENET1K_V1)\n",
    "\n",
    "# Freeze backbone\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Replace classifier head\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Linear(model.classifier.in_features, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.3),\n",
    "    nn.Linear(256, num_classes)\n",
    ")\n",
    "\n",
    "model = model.to(device)\n",
    "trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Trainable parameters: {trainable:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12461b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LR, weight_decay=1e-4)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4db626",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = torch.amp.GradScaler(device.type) if USE_CUDA else None\n",
    "amp_dtype = torch.float16 if USE_CUDA else torch.float32\n",
    "\n",
    "def train_epoch(model, loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    loss_sum, correct, total = 0, 0, 0\n",
    "    \n",
    "    for images, labels in tqdm(loader, desc='Train', leave=False):\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        labels = labels.to(device, non_blocking=True)\n",
    "        \n",
    "        with torch.amp.autocast(device.type, dtype=amp_dtype, enabled=USE_CUDA):\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "        \n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        if scaler:\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        loss_sum += loss.item() * images.size(0)\n",
    "        correct += (outputs.argmax(1) == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "    \n",
    "    return loss_sum / total, correct / total\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, criterion):\n",
    "    model.eval()\n",
    "    loss_sum, correct, total = 0, 0, 0\n",
    "    \n",
    "    for images, labels in tqdm(loader, desc='Eval', leave=False):\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        labels = labels.to(device, non_blocking=True)\n",
    "        \n",
    "        with torch.amp.autocast(device.type, dtype=amp_dtype, enabled=USE_CUDA):\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "        \n",
    "        loss_sum += loss.item() * images.size(0)\n",
    "        correct += (outputs.argmax(1) == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "    \n",
    "    return loss_sum / total, correct / total\n",
    "\n",
    "# Warmup\n",
    "_ = model(torch.randn(BATCH_SIZE, 3, IMAGE_SIZE, IMAGE_SIZE, device=device))\n",
    "if USE_CUDA:\n",
    "    torch.cuda.synchronize()\n",
    "elif USE_MPS:\n",
    "    torch.mps.synchronize()\n",
    "print(\"GPU initialized\" if device.type != 'cpu' else \"Running on CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f10ad21",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "best_acc = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer)\n",
    "    val_loss, val_acc = evaluate(model, val_loader, criterion)\n",
    "    scheduler.step()\n",
    "    \n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    \n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        torch.save({'model_state_dict': model.state_dict(), \n",
    "                    'class_names': class_names, 'accuracy': best_acc}, MODEL_PATH)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1:02d}/{EPOCHS} | Train: {train_acc:.4f} | Val: {val_acc:.4f} | Best: {best_acc:.4f}\")\n",
    "\n",
    "print(f\"\\nTraining complete. Best validation accuracy: {best_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdac93d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "ax1.plot(history['train_loss'], label='Train')\n",
    "ax1.plot(history['val_loss'], label='Validation')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.legend()\n",
    "ax1.set_title('Training Loss')\n",
    "\n",
    "ax2.plot(history['train_acc'], label='Train')\n",
    "ax2.plot(history['val_acc'], label='Validation')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.legend()\n",
    "ax2.set_title('Training Accuracy')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, 'training_curves.png'), dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d176a1e0",
   "metadata": {},
   "source": [
    "## Test Set Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a57ac82",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(MODEL_PATH, weights_only=False)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "print(f\"Loaded best model (validation accuracy: {checkpoint['accuracy']:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90683395",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds, test_labels_list = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in tqdm(test_loader, desc='Testing'):\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        with torch.amp.autocast(device.type, dtype=amp_dtype, enabled=USE_CUDA):\n",
    "            preds = model(images).argmax(1)\n",
    "        test_preds.extend(preds.cpu().numpy())\n",
    "        test_labels_list.extend(labels.numpy())\n",
    "\n",
    "print(\"\\nTEST SET RESULTS\")\n",
    "print(\"=\" * 50)\n",
    "print(classification_report(test_labels_list, test_preds, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15cda787",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(test_labels_list, test_preds)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix - Test Set')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, 'confusion_matrix.png'), dpi=150)\n",
    "plt.show()\n",
    "\n",
    "test_acc = (np.array(test_preds) == np.array(test_labels_list)).mean()\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe35d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 50)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Model: DenseNet-121 (frozen backbone)\")\n",
    "print(f\"Validation Accuracy: {best_acc:.4f}\")\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "print(f\"Saved: {MODEL_PATH}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
